# Use an official PyTorch base image with CUDA 12.1, matching your torch version
FROM pytorch/pytorch:2.2.2-cuda12.1-cudnn8-runtime

# Set the working directory inside the container
WORKDIR /app

# Install git, which is useful for some package installations, and clean up
RUN apt-get update && apt-get install -y git && \
    rm -rf /var/lib/apt/lists/*

# Copy the requirements file first to leverage Docker's layer caching
COPY requirements.txt .

# Install all Python dependencies from your requirements file
RUN pip install --no-cache-dir -r requirements.txt

# Copy your application code and data into the container
# Assumes 'src' and 'data' directories are in the build context root
COPY ./src ./src
COPY ./data ./data

# Expose the port Streamlit runs on
EXPOSE 8501

# The command to run when the container starts
# This launches your Streamlit dashboard and makes it accessible
CMD ["streamlit", "run", "src/app.py", "--server.port=8501", "--server.address=0.0.0.0"]
